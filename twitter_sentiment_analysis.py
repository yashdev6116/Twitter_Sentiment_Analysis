# -*- coding: utf-8 -*-
"""Twitter_Sentiment_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wr21RGhnXco5YSk95Rm4WikBavpG77Li
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import seaborn as sns
from wordcloud import WordCloud
import spacy

from google.colab import files
upload=files.upload()

df_train=pd.read_csv('/content/twitter_training.csv')
df_val=pd.read_csv('/content/twitter_validation.csv')

df_train.info()

df_train['Positive'].value_counts()

df_val.info()

# Calculate class counts
class_counts = df_train['Positive'].value_counts().reset_index()
class_counts.columns = ['Class', 'Count']

# Calculate the total number of images in train_df
total_images = len(df_train)

# Calculate the percentage for each class based on the total number of images
class_counts['Percentage'] = (class_counts['Count'] / total_images) * 100

# Sort the dataframe by count
class_counts = class_counts.sort_values(by='Count', ascending=False)

# Create the pie chart using matplotlib
plt.figure(figsize=(10, 8))
plt.pie(class_counts['Percentage'], labels=class_counts['Class'], autopct='%1.1f%%', startangle=140)
plt.title('Class Balance (Percentage)')
plt.axis('equal')
plt.tight_layout()
plt.show()

# Distribution of Sentiments
sns.countplot(data=df_train, x='Positive')
plt.title('Distribution of Sentiments')
plt.show()

# Text Length Distribution
df_train['text_length'] = df_train['text'].apply(len)
sns.histplot(data=df_train, x='text_length', hue='Positive', kde=True)
plt.title('Text Length Distribution by Sentiment')
plt.show()

# Word Frequency Analysis (for each sentiment class)
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(df_train[df_train['Positive'] == 1]['text']))
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.title('Word Cloud for Positive Tweets')
plt.axis('off')
plt.show()

nlp = spacy.load("en_core_web_sm")

def preprocess(text):
    if pd.isnull(text):
        return ""
    doc = nlp(text)
    filtered_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]
    return " ".join(filtered_tokens)

df_train.rename(columns={"im getting on borderlands and i will murder you all ,": "text"}, inplace=True)

df_train['text']=df_train['text'].apply(preprocess)

df_train

le = LabelEncoder()
df_train['Positive'] = le.fit_transform(df_train['Positive'])

df_train=df_train.drop(['Borderlands','2401'],axis=1)
df_train

df_val=df_val.drop(['3364','Facebook'],axis=1)
df_val

df_val.columns

df_val.rename(columns={"I mentioned on Facebook that I was struggling for motivation to go for a run the other day, which has been translated by Tomâ€™s great auntie as â€˜Hayley canâ€™t get out of bedâ€™ and told to his grandma, who now thinks Iâ€™m a lazy, terrible person ðŸ¤£": "text"}, inplace=True)

df_val

df_val['text']=df_val['text'].apply(preprocess)
df_val

df_val['Irrelevant'] = le.fit_transform(df_val['Irrelevant'])
df_val

df_val.rename(columns={"Irrelevant": "Positive"}, inplace=True)

combined_df = pd.concat([df_train, df_val], ignore_index=True)
combined_df

X_train, X_test, y_train, y_test = train_test_split(combined_df['text'], combined_df['Positive'],
                                                    test_size=0.2, random_state=42, stratify=combined_df['Positive'])

clf = Pipeline([
    ('vectorizer_tri_grams', TfidfVectorizer()),
    ('RandomForest', (RandomForestClassifier()))
])

clf.fit(X_train, y_train)

pred = clf.predict(X_test)
print(accuracy_score(y_test, pred))